{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The code aims to modify the analysis of Yenni et al. (2012):\n",
    "#### - corrected the SoS calculation\n",
    "#### - modified the parameters to paper's description: \"r2 integers from 11 to 20\"\n",
    "#### - removed the additional filter S1 >= 1 & S2 >= 1\n",
    "#### - did not truncate the values\n",
    "#### - included one additional metric: CA\n",
    "#### - employed PCA to the variables\n",
    "\n",
    "#### their original code: https://github.com/gmyenni/RareStabilizationSimulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analyN_function.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyN(r1, r2, a1, a12, a21, a2):\n",
    "    N1 = (r1 - 1 - (a12 / a2) * (r2 - 1)) / (a1 - a21 * a12 / a2)\n",
    "    N2 = (r2 - 1 - (a21 / a1) * (r1 - 1)) / (a2 - a21 * a12 / a1)\n",
    "    if np.isinf(N1) or np.isinf(N2) or np.isnan(N1) or np.isnan(N2):\n",
    "        initialNsp1 = 0\n",
    "        initialNsp2 = 0\n",
    "        N = np.zeros((100, 2))\n",
    "        N[0, :] = [initialNsp1, initialNsp2]   \n",
    "        for i in range(1, 100):\n",
    "            N[i, 0] = max((r1 - 1 - a12 * N[i-1, 1]) / a1, 0)\n",
    "            N[i, 1] = max((r2 - 1 - a21 * N[i-1, 0]) / a2, 0)\n",
    "        N1 = np.mean(N[:, 0])\n",
    "        N2 = np.mean(N[:, 1])\n",
    "    if N1 < 0 and N2 >= 0:\n",
    "        N1 = 0\n",
    "        N2 = (r2 - 1) / a2\n",
    "    elif N2 < 0 and N1 >= 0:\n",
    "        N2 = 0\n",
    "        N1 = (r1 - 1) / a1\n",
    "    return N1, N2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def competitive_ability(r1, r2, a11, a22, a12, a21):\n",
    "    CA1 = (r1 - 1) / np.sqrt(a12 * a11)\n",
    "    CA2 = (r2 - 1) / np.sqrt(a21 * a22)\n",
    "    return CA1, CA2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# getNFD.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(l1, l2, a11, a12, a21, a22, N1, N2):\n",
    "    CoexistRank = 0 if N1 < 1 else 1\n",
    "#     The code of Yenni et al. replaced l1 with l2 in the numerator:\n",
    "#     S1 = l2 / (1 + (a12 / a22) * (l2 - 1))\n",
    "#     S2 = l1 / (1 + (a21 / a11) * (l1 - 1))\n",
    "#     # Corrected Strength of Stabilization:\n",
    "    S1 = l1 / (1 + (a12 / a22) * (l2 - 1))\n",
    "    S2 = l2 / (1 + (a21 / a11) * (l1 - 1))\n",
    "    E1, E2 = l1 / l2, l2 / l1  # Fitness equivalence\n",
    "    Asy = S1 - S2  # Asymmetry\n",
    "    Rare = 0 if N1 == 0 and N2 == 0 else N1 / (N1 + N2)\n",
    "    # Calculating covariance for SoS\n",
    "    x = np.array([N1, N2])\n",
    "    y_sos = np.array([S1, S2])\n",
    "    cor_matrix_sos = np.cov(x, y_sos)\n",
    "    cor_sos = cor_matrix_sos[0, 1]  # Extracting the correlation between N and SoS\n",
    "    Rank = 0 if N1 == 0 and N2 == 0 else (2 if N1 / (N1 + N2) <= 0.25 else 1)\n",
    "    # Competitive Ability\n",
    "    CA1, CA2 = competitive_ability(l1, l2, a11, a22, a12, a21)\n",
    "    # Calculating covariance for CA\n",
    "    y_ca = np.array([CA1, CA2])\n",
    "    cor_matrix_ca = np.cov(x, y_ca)\n",
    "    cor_ca = cor_matrix_ca[0, 1]  # Extracting the correlation between N and CA\n",
    "    return {\"CoexistRank\": CoexistRank, \"E1\": E1, \"S1\": S1, \"E2\": E2, \"S2\": S2, \"Asy\": Asy, \"cor_sos\": cor_sos, \"cor_ca\": cor_ca, \"Rare\": Rare, \"Rank\": Rank, \"CA1\": CA1, \"CA2\": CA2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# annualplant_2spp_det_par.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data():\n",
    "    # Defines frequency-dependent parameters\n",
    "    l1_v = np.arange(15, 21)\n",
    "    l2_v = np.arange(11, 21)\n",
    "    a11_v = np.array([0.1, 0.3, 0.5, 0.7, 0.9, 1, 1.5, 2, 2.5, 3])\n",
    "    a12_v = np.array([0.1, 0.3, 0.5, 0.7, 0.9, 1])\n",
    "    a21_v = np.array([0.1, 0.3, 0.5, 0.7, 0.9, 1])\n",
    "    a22_v = np.array([0.1, 0.3, 0.5, 0.7, 0.9, 1])\n",
    "    # Generate all combinations of parameters using NumPy's meshgrid\n",
    "    mesh = np.array(np.meshgrid(l1_v, l2_v, a11_v, a12_v, a21_v, a22_v)).T.reshape(-1, 6)\n",
    "    return mesh\n",
    "\n",
    "def Sim(k, mesh_row):\n",
    "    l1, l2, a11, a12, a21, a22 = mesh_row\n",
    "    N1, N2 = analyN(l1, l2, a11, a12, a21, a22)\n",
    "    metrics = calculate_metrics(l1, l2, a11, a12, a21, a22, N1, N2)\n",
    "    return {**metrics, \"l1\": l1, \"l2\": l2, \"a11\": a11, \"a12\": a12, \"a21\": a21, \"a22\": a22}\n",
    "\n",
    "def postprocess_results(results, outfile):\n",
    "    column_order = ['l1', 'l2', 'a11', 'a12', 'a21', 'a22', 'N1', 'N2', 'E1', 'S1', 'E2', 'S2', 'Rank', 'CoexistRank', 'Asy', 'cor_sos', 'cor_ca', 'Rare', 'CA1', 'CA2']\n",
    "    simul = pd.DataFrame(results, columns=column_order)\n",
    "    simul.to_csv(outfile, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cor_figure.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cor_figure():\n",
    "    dat_det = pd.read_csv(\"csv/annplant_2spp_det_rare.csv\")\n",
    "    dat_det = dat_det.query('Rank == 2').copy() #  & S1 >= 1 & S2 >= 1\n",
    "    dat_det.reset_index(drop=True, inplace=True)\n",
    "#     dat_det = np.trunc(dat_det * 100) / 100.0\n",
    "    dat_det.sort_values(by=['a22', 'a21', 'a12', 'a11', 'l2', 'l1'], inplace=True)\n",
    "    dat_det.to_csv(\"csv/annplant_2spp_det_rare_filtered.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pca(simul):\n",
    "    # Apply PCA to SoS\n",
    "    features_sos = ['S1', 'S2']\n",
    "    x_sos = StandardScaler().fit_transform(simul[features_sos].values)\n",
    "    pca_sos = PCA(n_components=1)\n",
    "    principalComponent_sos = pca_sos.fit_transform(x_sos)\n",
    "    simul['SoS_PCA'] = principalComponent_sos[:, 0]\n",
    "    variance_sos = pca_sos.explained_variance_ratio_.sum() * 100\n",
    "    print(f\"PCA captured {variance_sos:.2f}% of the variance for the SoS pair.\")\n",
    "    # Apply PCA to FE\n",
    "    features_fe = ['E1', 'E2']\n",
    "    x_fe = StandardScaler().fit_transform(simul[features_fe].values)\n",
    "    pca_fe = PCA(n_components=1)\n",
    "    principalComponent_fe = pca_fe.fit_transform(x_fe)\n",
    "    simul['FE_PCA'] = principalComponent_fe[:, 0]\n",
    "    variance_fe = pca_fe.explained_variance_ratio_.sum() * 100\n",
    "    print(f\"PCA captured {variance_fe:.2f}% of the variance for the FE pair.\")\n",
    "    # Apply PCA to CA\n",
    "    features_ca = ['CA1', 'CA2']\n",
    "    x_ca = StandardScaler().fit_transform(simul[features_ca].values)\n",
    "    pca_ca = PCA(n_components=1)\n",
    "    principalComponent_ca = pca_ca.fit_transform(x_ca)\n",
    "    simul['CA_PCA'] = principalComponent_ca[:, 0]\n",
    "    variance_ca = pca_ca.explained_variance_ratio_.sum() * 100\n",
    "    print(f\"PCA captured {variance_ca:.2f}% of the variance for the CA pair.\")\n",
    "    return simul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# figures_det.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_logistic_regression(dat, analysis_type):\n",
    "    predictors_map = {\n",
    "        'PCA_SoS': ['SoS_PCA', 'cor_sos'],\n",
    "        'PCA_CA': ['CA_PCA', 'cor_ca'],\n",
    "        'NonPCA_SoS': ['S1', 'E1', 'cor_sos'],\n",
    "        'NonPCA_CA': ['CA1', 'cor_ca']\n",
    "    }\n",
    "    predictors = predictors_map[analysis_type]\n",
    "    X = sm.add_constant(dat[predictors])\n",
    "    y = dat['CoexistRank']\n",
    "    model = sm.GLM(y, X, family=sm.families.Binomial())\n",
    "    result = model.fit()\n",
    "    print(f\"\\n{analysis_type} Analysis:\\n{result.summary()}\")\n",
    "    return result\n",
    "\n",
    "def calculate_proportions(dat, correlation_type):\n",
    "    proportions = {}\n",
    "    for cor_type in [correlation_type]:\n",
    "        proportions[f'positive_coexistence_{cor_type}'] = len(dat[(dat[cor_type] >= 0) & (dat['CoexistRank'] == 1)])\n",
    "        proportions[f'positive_exclusion_{cor_type}'] = len(dat[(dat[cor_type] >= 0) & (dat['CoexistRank'] == 0)])\n",
    "        proportions[f'negative_coexistence_{cor_type}'] = len(dat[(dat[cor_type] < 0) & (dat['CoexistRank'] == 1)])\n",
    "        proportions[f'negative_exclusion_{cor_type}'] = len(dat[(dat[cor_type] < 0) & (dat['CoexistRank'] == 0)])\n",
    "    return proportions\n",
    "\n",
    "def report_coexistence_analysis(proportions, correlation_type):\n",
    "    positive_key = f'positive_coexistence_{correlation_type}'\n",
    "    negative_key = f'negative_coexistence_{correlation_type}'\n",
    "    neg_confint = proportion_confint(count=proportions[negative_key], nobs=proportions[negative_key] + proportions[f'negative_exclusion_{correlation_type}'], alpha=0.05, method='wilson')\n",
    "    pos_confint = proportion_confint(count=proportions[positive_key], nobs=proportions[positive_key] + proportions[f'positive_exclusion_{correlation_type}'], alpha=0.05, method='wilson')\n",
    "    print(f\"\\nAnalysis on Negative \\u03BD for {correlation_type.upper()}:\")\n",
    "    print(f\"Proportion of coexistence with \\u03BD < 0: {proportions[negative_key] / (proportions[negative_key] + proportions[f'negative_exclusion_{correlation_type}']):.4f} (95% CI: {neg_confint})\")\n",
    "    print(f\"Proportion of coexistence with \\u03BD \\u2265 0: {proportions[positive_key] / (proportions[positive_key] + proportions[f'positive_exclusion_{correlation_type}']):.4f} (95% CI: {pos_confint})\")\n",
    "\n",
    "def analyze_coexistence_effect(file_path):\n",
    "    dat = pd.read_csv(file_path)\n",
    "    original_dat = dat.copy()\n",
    "    models_results = {}\n",
    "    scenarios = ['NonPCA', 'PCA']\n",
    "    for scenario in scenarios:\n",
    "        dat = apply_pca(original_dat) if scenario == 'PCA' else original_dat.copy()\n",
    "        for correlation_type in ['SoS', 'CA']:\n",
    "            analysis_type = f'{scenario}_{correlation_type}'\n",
    "            correlation_column = 'cor_sos' if correlation_type == 'SoS' else 'cor_ca'\n",
    "            if correlation_column not in dat.columns:\n",
    "                continue\n",
    "            print(f\"\\n--- Analysis for {analysis_type} ---\")\n",
    "            result = perform_logistic_regression(dat, analysis_type)\n",
    "            aic = result.aic\n",
    "            bic = result.bic\n",
    "            n = len(dat)\n",
    "            k = len(result.params)\n",
    "            aicc = aic + (2 * k * (k + 1)) / (n - k - 1)\n",
    "            # Store AIC, AICC, and BIC in models_results for each analysis type\n",
    "            models_results[analysis_type] = {'AIC': aic, 'AICC': aicc, 'BIC': bic}\n",
    "            proportions = calculate_proportions(dat, correlation_column)\n",
    "            report_coexistence_analysis(proportions, correlation_column)\n",
    "            table_data = {\n",
    "                '\\u03BD \\u2265 0': [proportions[f'positive_coexistence_{correlation_column}'], proportions[f'positive_exclusion_{correlation_column}']],\n",
    "                '\\u03BD < 0': [proportions[f'negative_coexistence_{correlation_column}'], proportions[f'negative_exclusion_{correlation_column}']]\n",
    "            }\n",
    "            table_df = pd.DataFrame(table_data, index=['Coexistence', 'Exclusion'])\n",
    "            print(f\"Coexistence and Exclusion based on \\u03BD for {analysis_type}:\\n\", table_df)\n",
    "            # Proportion of coexistence calculations and confidence intervals\n",
    "            for coexistence_type in ['positive', 'negative']:\n",
    "                coexist_col = f'{coexistence_type}_coexistence_{correlation_column}'\n",
    "                total_col = f'{coexistence_type}_exclusion_{correlation_column}'\n",
    "                proportion = proportions[coexist_col] / (proportions[coexist_col] + proportions[total_col]) if (proportions[coexist_col] + proportions[total_col]) > 0 else 0\n",
    "                confint = proportion_confint(count=proportions[coexist_col], nobs=proportions[coexist_col] + proportions[total_col], alpha=0.05, method='wilson')\n",
    "#                 print(f\"\\nProportion of {coexistence_type} coexistence for {analysis_type}: {proportion:.4f} (95% CI: {confint})\")\n",
    "            # Decision making based on confidence intervals\n",
    "            if coexistence_type == 'negative':\n",
    "                if confint[1] < 0.5:\n",
    "                    print(f\"Higher coexistence observed with \\u03BD \\u2265 0 for {analysis_type}, not supporting the authors' claim.\")\n",
    "                elif confint[0] > 0.5:\n",
    "                    print(f\"Higher coexistence observed with \\u03BD < 0 for {analysis_type}, supporting the authors' claim.\")\n",
    "                else:\n",
    "                    print(f\"Confidence intervals for proportions overlap for {analysis_type}, suggesting the effect of \\u03BD on coexistence is inconclusive.\")\n",
    "    return models_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_selection(models_results):\n",
    "    # Define the scenarios\n",
    "    scenarios = ['NonPCA_SoS', 'PCA_SoS', 'NonPCA_CA', 'PCA_CA']\n",
    "    # Prepare a dictionary to store AIC, AICC, and BIC for SoS+FE and CA\n",
    "    criteria = {scenario: {'AIC': None, 'AICC': None, 'BIC': None} for scenario in scenarios}\n",
    "    # Populate the dictionary with values from models_results\n",
    "    for scenario in scenarios:\n",
    "        if scenario in models_results:\n",
    "            criteria[scenario]['AIC'] = models_results[scenario]['AIC']\n",
    "            criteria[scenario]['AICC'] = models_results[scenario]['AICC']\n",
    "            criteria[scenario]['BIC'] = models_results[scenario]['BIC']\n",
    "    # Convert the dictionary to a pandas DataFrame for easy tabular display\n",
    "    criteria_df = pd.DataFrame(criteria).T\n",
    "    criteria_df.index.name = 'Scenario'\n",
    "    criteria_df.columns.name = 'Criteria'\n",
    "    print(\"\\nModel Selection Criteria Table:\")\n",
    "    print(criteria_df)\n",
    "    best_aic = criteria_df['AIC'].idxmin()\n",
    "    best_aicc = criteria_df['AICC'].idxmin()\n",
    "    best_bic = criteria_df['BIC'].idxmin()\n",
    "    print(f\"\\nOverall best model based on AIC: {best_aic} (AIC: {criteria_df.loc[best_aic, 'AIC']})\")\n",
    "    print(f\"Overall best model based on AICc: {best_aicc} (AICc: {criteria_df.loc[best_aicc, 'AICC']})\")\n",
    "    print(f\"Overall best model based on BIC: {best_bic} (BIC: {criteria_df.loc[best_bic, 'BIC']})\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis for All Scenarios:\n",
      "\n",
      "--- Analysis for NonPCA_SoS ---\n",
      "\n",
      "NonPCA_SoS Analysis:\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:            CoexistRank   No. Observations:                60725\n",
      "Model:                            GLM   Df Residuals:                    60721\n",
      "Model Family:                Binomial   Df Model:                            3\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -34949.\n",
      "Date:                Wed, 27 Mar 2024   Deviance:                       69898.\n",
      "Time:                        16:47:52   Pearson chi2:                 7.24e+04\n",
      "No. Iterations:                     5   Pseudo R-squ. (CS):             0.1301\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -1.5161      0.048    -31.777      0.000      -1.610      -1.423\n",
      "S1             0.8770      0.014     62.431      0.000       0.849       0.905\n",
      "E1            -0.1022      0.038     -2.711      0.007      -0.176      -0.028\n",
      "cor_sos       -0.0026      0.000    -20.347      0.000      -0.003      -0.002\n",
      "==============================================================================\n",
      "\n",
      "Analysis on Negative ν for COR_SOS:\n",
      "Proportion of coexistence with ν < 0: 0.2842 (95% CI: (0.27751114742186744, 0.29092171483214735))\n",
      "Proportion of coexistence with ν ≥ 0: 0.3714 (95% CI: (0.3668757655545365, 0.37597252820042826))\n",
      "Coexistence and Exclusion based on ν for NonPCA_SoS:\n",
      "              ν ≥ 0  ν < 0\n",
      "Coexistence  16100   4938\n",
      "Exclusion    27248  12439\n",
      "Higher coexistence observed with ν ≥ 0 for NonPCA_SoS, not supporting the authors' claim.\n",
      "\n",
      "--- Analysis for NonPCA_CA ---\n",
      "\n",
      "NonPCA_CA Analysis:\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:            CoexistRank   No. Observations:                60725\n",
      "Model:                            GLM   Df Residuals:                    60722\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -37755.\n",
      "Date:                Wed, 27 Mar 2024   Deviance:                       75509.\n",
      "Time:                        16:47:52   Pearson chi2:                 6.13e+04\n",
      "No. Iterations:                     6   Pseudo R-squ. (CS):            0.04589\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.1371      0.015     -9.083      0.000      -0.167      -0.108\n",
      "CA1           -0.0132      0.000    -32.348      0.000      -0.014      -0.012\n",
      "cor_ca        -0.0003   9.18e-06    -37.162      0.000      -0.000      -0.000\n",
      "==============================================================================\n",
      "\n",
      "Analysis on Negative ν for COR_CA:\n",
      "Proportion of coexistence with ν < 0: 0.2830 (95% CI: (0.2763178098906173, 0.28972248514837556))\n",
      "Proportion of coexistence with ν ≥ 0: 0.3718 (95% CI: (0.3672964372426985, 0.37639225974685336))\n",
      "Coexistence and Exclusion based on ν for NonPCA_CA:\n",
      "              ν ≥ 0  ν < 0\n",
      "Coexistence  16129   4909\n",
      "Exclusion    27248  12439\n",
      "Higher coexistence observed with ν ≥ 0 for NonPCA_CA, not supporting the authors' claim.\n",
      "PCA captured 52.86% of the variance for the SoS pair.\n",
      "PCA captured 98.65% of the variance for the FE pair.\n",
      "PCA captured 51.37% of the variance for the CA pair.\n",
      "\n",
      "--- Analysis for PCA_SoS ---\n",
      "\n",
      "PCA_SoS Analysis:\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:            CoexistRank   No. Observations:                60725\n",
      "Model:                            GLM   Df Residuals:                    60722\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -37618.\n",
      "Date:                Wed, 27 Mar 2024   Deviance:                       75236.\n",
      "Time:                        16:47:52   Pearson chi2:                 5.93e+04\n",
      "No. Iterations:                     6   Pseudo R-squ. (CS):            0.05017\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.4713      0.011    -43.616      0.000      -0.492      -0.450\n",
      "SoS_PCA        0.1574      0.012     13.057      0.000       0.134       0.181\n",
      "cor_sos       -0.0044      0.000    -25.437      0.000      -0.005      -0.004\n",
      "==============================================================================\n",
      "\n",
      "Analysis on Negative ν for COR_SOS:\n",
      "Proportion of coexistence with ν < 0: 0.2842 (95% CI: (0.27751114742186744, 0.29092171483214735))\n",
      "Proportion of coexistence with ν ≥ 0: 0.3714 (95% CI: (0.3668757655545365, 0.37597252820042826))\n",
      "Coexistence and Exclusion based on ν for PCA_SoS:\n",
      "              ν ≥ 0  ν < 0\n",
      "Coexistence  16100   4938\n",
      "Exclusion    27248  12439\n",
      "Higher coexistence observed with ν ≥ 0 for PCA_SoS, not supporting the authors' claim.\n",
      "\n",
      "--- Analysis for PCA_CA ---\n",
      "\n",
      "PCA_CA Analysis:\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:            CoexistRank   No. Observations:                60725\n",
      "Model:                            GLM   Df Residuals:                    60722\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -37659.\n",
      "Date:                Wed, 27 Mar 2024   Deviance:                       75318.\n",
      "Time:                        16:47:52   Pearson chi2:                 6.06e+04\n",
      "No. Iterations:                     6   Pseudo R-squ. (CS):            0.04890\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.4246      0.009    -44.927      0.000      -0.443      -0.406\n",
      "CA_PCA        -0.5615      0.016    -34.764      0.000      -0.593      -0.530\n",
      "cor_ca        -0.0005   1.26e-05    -40.312      0.000      -0.001      -0.000\n",
      "==============================================================================\n",
      "\n",
      "Analysis on Negative ν for COR_CA:\n",
      "Proportion of coexistence with ν < 0: 0.2830 (95% CI: (0.2763178098906173, 0.28972248514837556))\n",
      "Proportion of coexistence with ν ≥ 0: 0.3718 (95% CI: (0.3672964372426985, 0.37639225974685336))\n",
      "Coexistence and Exclusion based on ν for PCA_CA:\n",
      "              ν ≥ 0  ν < 0\n",
      "Coexistence  16129   4909\n",
      "Exclusion    27248  12439\n",
      "Higher coexistence observed with ν ≥ 0 for PCA_CA, not supporting the authors' claim.\n",
      "\n",
      "Model Selection Criteria Table:\n",
      "Criteria             AIC          AICC            BIC\n",
      "Scenario                                             \n",
      "NonPCA_SoS  69906.021057  69906.021716 -598889.798029\n",
      "PCA_SoS     75242.299258  75242.299653 -593562.533939\n",
      "NonPCA_CA   75515.096063  75515.096459 -593289.737133\n",
      "PCA_CA      75323.688800  75323.689196 -593481.144396\n",
      "\n",
      "Overall best model based on AIC: NonPCA_SoS (AIC: 69906.02105725418)\n",
      "Overall best model based on AICc: NonPCA_SoS (AICc: 69906.02171601572)\n",
      "Overall best model based on BIC: NonPCA_SoS (BIC: -598889.7980285088)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    # Specify paths for the output files\n",
    "    initial_output_file = \"csv/annplant_2spp_det_rare.csv\"\n",
    "    filtered_output_file = \"csv/annplant_2spp_det_rare_filtered.csv\"\n",
    "    # Generate the parameter mesh\n",
    "    mesh = preprocess_data()\n",
    "    # Run the simulation for each parameter set in the mesh\n",
    "    results = [Sim(k, row) for k, row in enumerate(mesh)]\n",
    "    # Convert the list of dictionaries into a DataFrame and save to CSV\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(initial_output_file, index=False)\n",
    "    # Apply filters and generate the filtered data CSV\n",
    "    cor_figure()\n",
    "    # Initialize dictionary for model results\n",
    "    models_results = {}\n",
    "    # Analysis for all scenarios using the filtered dataset\n",
    "    print(\"Analysis for All Scenarios:\")\n",
    "    results = analyze_coexistence_effect(filtered_output_file)\n",
    "    models_results.update(results)\n",
    "    # Model Selection based on AIC, AICc, and BIC\n",
    "    model_selection(models_results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
