{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The code is a modification of the Yenni et al. (2012) analysis:\n",
    "#### - runs the analysis with and without the filter S1 >= 1 & S2 >= 1\n",
    "#### - includes Cushing et al. (2004) analytical results\n",
    "\n",
    "#### their original code: https://github.com/gmyenni/RareStabilizationSimulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "from tqdm import tqdm\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analyN_function.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEqDensity(r1, r2, a11, a12, a21, a22): # Coexistence equilibrium populations\n",
    "    denominator1 = a11 - (a21 * a12) / a22\n",
    "    denominator2 = a22 - (a21 * a12) / a11\n",
    "    N1 = (r1 - 1 - (a12 / a22) * (r2 - 1)) / denominator1 if denominator1 != 0 else np.nan\n",
    "    N2 = (r2 - 1 - (a21 / a11) * (r1 - 1)) / denominator2 if denominator2 != 0 else np.nan\n",
    "    if np.isinf(N1) or np.isinf(N2) or np.isnan(N1) or np.isnan(N2):\n",
    "        initialNsp1 = 0\n",
    "        initialNsp2 = 0\n",
    "        N = np.zeros((100, 2))\n",
    "        N[0, :] = [initialNsp1, initialNsp2]   \n",
    "        for i in range(1, 100):\n",
    "            N[i, 0] = max((r1 - 1 - a12 * N[i-1, 1]) / a11, 0)\n",
    "            N[i, 1] = max((r2 - 1 - a21 * N[i-1, 0]) / a22, 0)\n",
    "        N1 = np.mean(N[:, 0])\n",
    "        N2 = np.mean(N[:, 1])\n",
    "    if N1 < 0 and N2 >= 0:\n",
    "        N1, N2 = 0.0, (r2 - 1) / a22 if a22 != 0 else 0.0\n",
    "    elif N2 < 0 and N1 >= 0:\n",
    "        N1, N2 = (r1 - 1) / a11 if a11 != 0 else 0.0, 0.0\n",
    "    elif N1 < 0 and N2 < 0:\n",
    "        N1, N2 = 0.0, 0.0\n",
    "    return N1, N2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# getNFD.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def SOS(r1, r2, a11, a12, a21, a22):\n",
    "    S1 = r2 / (1 + (a12 / a22) * (r2 - 1))\n",
    "    S2 = r1 / (1 + (a21 / a11) * (r1 - 1))\n",
    "    return S1, S2\n",
    "\n",
    "@jit\n",
    "def getPCG(r1, r2, a11, a12, a21, a22, N1, N2): # Per capita growth rate calculation\n",
    "    newN1 = r1 * N1 / (1 + a11 * N1 + a12 * N2) if N1 > 0 else np.nan\n",
    "    newN2 = r2 * N2 / (1 + a22 * N2 + a21 * N1) if N2 > 0 else np.nan\n",
    "    PGR1 = np.log(newN1) - np.log(N1) if N1 > 0 else np.nan\n",
    "    PGR2 = np.log(newN2) - np.log(N2) if N2 > 0 else np.nan\n",
    "    return PGR1, PGR2\n",
    "\n",
    "@jit\n",
    "def calculate_metrics(r1, r2, a11, a12, a21, a22, N1, N2, extinc_crit_1=True):\n",
    "    S1, S2 = SOS(r1, r2, a11, a12, a21, a22) # Strength of Stabilization\n",
    "    FE1, FE2 = r1 / r2, r2 / r1 # Fitness equivalence\n",
    "    Asy = S1 - S2 # Asymmetry\n",
    "    Rare = 0 if N1 == 0 and N2 == 0 else N1 / (N1 + N2)\n",
    "    # Calculating covariance for SoS\n",
    "    x = np.array([N1, N2])\n",
    "    y_sos = np.array([S1, S2])\n",
    "    cor_matrix_sos = np.cov(x, y_sos)\n",
    "    cor_sos = cor_matrix_sos[0, 1] # Extracting the correlation between N and SoS\n",
    "    Rank = 0 if N1 == 0 and N2 == 0 else (2 if N1 / (N1 + N2) <= 0.25 else 1)\n",
    "    # Equilibrium points\n",
    "    E1 = (r1 - 1) / a11\n",
    "    E2 = (r2 - 1) / a22\n",
    "    P = (r1 - 1) / a12\n",
    "    Q = (r2 - 1) / a21\n",
    "    # Calculate conditions for A, B, C, D\n",
    "    A = P > E2 and E1 > Q\n",
    "    B = E2 > P and Q > E1\n",
    "    C = P > E2 and Q > E1\n",
    "    D = E2 > P and E1 > Q\n",
    "    # Call getPCG to calculate PGR1 and PGR2\n",
    "    PGR1, PGR2 = getPCG(r1, r2, a11, a12, a21, a22, N1, N2)\n",
    "    if extinc_crit_1:\n",
    "        Coexist = 0 if N1 < 1 or N2 < 1 else 1\n",
    "    else:\n",
    "        Coexist = 0 if N1 < 1.0e-6 or N2 < 1.0e-6 else 1\n",
    "    return {\"FE1\": FE1, \"S1\": S1, \"FE2\": FE2, \"S2\": S2, \"Rank\": Rank, \"Coexist\": Coexist, \"Asy\": Asy, \"cor_sos\": cor_sos, \"Rare\": Rare, \"PGR1\": PGR1, \"PGR2\": PGR2, \"A\": A, \"B\": B, \"C\": C, \"D\": D}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# annualplant_2spp_det_par.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(pars):\n",
    "    # Defines frequency-dependent parameters\n",
    "    if pars == 'r_code': # Their R code\n",
    "         r1_v = np.arange(10, 21, 1)\n",
    "         r2_v = np.arange(10, 21, 1)\n",
    "         a11_v = np.array([0.1, 0.3, 0.5, 0.7, 0.9, 1, 1.5, 2, 2.5, 3])\n",
    "         a12_v = np.array([0.1, 0.3, 0.5, 0.7, 0.9, 1])\n",
    "         a21_v = np.array([0.1, 0.3, 0.5, 0.7, 0.9, 1])\n",
    "         a22_v = np.array([0.1, 0.3, 0.5, 0.7, 0.9, 1])\n",
    "    elif pars == 'table1': # Reproduce their Table 1\n",
    "        r1_v = np.arange(15, 21, 1)\n",
    "        r2_v = np.arange(15, 21, 1)\n",
    "        a11_v = np.array([0.1, 0.3, 0.5, 0.7, 0.9, 1, 1.5, 2, 2.5, 3])\n",
    "        a12_v = np.array([0.1, 0.3, 0.5, 0.7, 0.9, 1])\n",
    "        a21_v = np.array([0.1, 0.3, 0.5, 0.7, 0.9, 1])\n",
    "        a22_v = np.array([0.1, 0.3, 0.5, 0.7, 0.9, 1])\n",
    "    elif pars == 'paper': # They describe in the paper\n",
    "         r1_v = np.arange(15, 21, 1)\n",
    "         r2_v = np.arange(11, 21, 1)\n",
    "         a11_v = np.array([0.7, 0.3, 0.5, 0.7, 0.9, 1, 1.5, 2, 2.5, 3])\n",
    "         a12_v = np.array([0.1, 0.3, 0.5, 0.7, 0.9, 1])\n",
    "         a21_v = np.array([0.1, 0.3, 0.5, 0.7, 0.9, 1])\n",
    "         a22_v = np.array([0.1, 0.3, 0.5, 0.7, 0.9, 1])\n",
    "    else: # minimal: Reduced set of parameters\n",
    "        r1_v = np.array([15, 17, 18, 20])\n",
    "        r2_v = np.array([15, 17, 18, 20])\n",
    "        a11_v = np.array([0.1, 1, 3])\n",
    "        a12_v = np.array([0.1, 0.5, 1])\n",
    "        a21_v = np.array([0.1, 0.5, 1])\n",
    "        a22_v = np.array([0.1, 0.5, 1])\n",
    "    # Generate all combinations of parameters using NumPy's meshgrid\n",
    "    mesh = np.array(np.meshgrid(r1_v, r2_v, a11_v, a12_v, a21_v, a22_v)).T.reshape(-1, 6)\n",
    "    return mesh\n",
    "\n",
    "def Sim(k, mesh_row, extinc_crit_1=False):\n",
    "    start_time = time.time()\n",
    "    r1, r2, a11, a12, a21, a22 = mesh_row\n",
    "    N1, N2 = getEqDensity(r1, r2, a11, a12, a21, a22)\n",
    "    metrics = calculate_metrics(r1, r2, a11, a12, a21, a22, N1, N2, extinc_crit_1)\n",
    "    execution_time = time.time() - start_time\n",
    "    return {**metrics, \"N1\": N1, \"N2\": N2, \"r1\": r1, \"r2\": r2, \"a11\": a11, \"a12\": a12, \"a21\": a21, \"a22\": a22}\n",
    "\n",
    "def postprocess_results(results, outfile):\n",
    "    column_order = ['r1', 'r2', 'a11', 'a12', 'a21', 'a22', 'N1', 'N2', 'FE1', 'S1', 'FE2', 'S2', 'Rank', 'Coexist', 'Asy', 'cor_sos', 'Rare', 'PGR1', 'PGR2', 'A', 'B', 'C', 'D']\n",
    "    simul = pd.DataFrame(results, columns=column_order)\n",
    "    simul.to_csv(outfile, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cor_figure.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cor_figure(filter, truncate=False):\n",
    "    dat_det = pd.read_csv(\"csv/annplant_2spp_det_rare.csv\")\n",
    "    if filter == 'inverted':\n",
    "        dat_det = dat_det.query('Rank == 2 & S1 < 1 & S2 < 1').copy()\n",
    "    elif filter == 'on':\n",
    "        dat_det = dat_det.query('Rank == 2 & S1 >= 1 & S2 >= 1').copy()\n",
    "    else: # 'off'\n",
    "        dat_det = dat_det.query('Rank == 2').copy()\n",
    "    dat_det.reset_index(drop=True, inplace=True)\n",
    "    if truncate:\n",
    "        dat_det = np.trunc(dat_det * 100) / 100.0\n",
    "    dat_det.sort_values(by=['a22', 'a21', 'a12', 'a11', 'r2', 'r1'], inplace=True)\n",
    "    dat_det.to_csv(f\"csv/annplant_2spp_det_rare_filtered_{filter}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# figures_det.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_logistic_regression(dat, analysis_type):\n",
    "    predictors_map = {\n",
    "        'SoS': ['S1', 'FE1', 'cor_sos'],\n",
    "    }    \n",
    "    predictors = predictors_map[analysis_type]\n",
    "    X = sm.add_constant(dat[predictors])\n",
    "    y = dat['Coexist']\n",
    "    model = sm.GLM(y, X, family=sm.families.Binomial())\n",
    "    result = model.fit()\n",
    "    print(result.summary())\n",
    "    coef = result.params\n",
    "    std_err = result.bse\n",
    "    z_scores = result.tvalues\n",
    "    p_values = result.pvalues\n",
    "    intercept = coef[0]\n",
    "    coef = coef[1:]\n",
    "    return intercept, coef, std_err, z_scores, p_values\n",
    "\n",
    "def calculate_proportions(dat, correlation_column):\n",
    "    proportions = {}\n",
    "    proportions[f'positive_coexistence_{correlation_column}'] = len(dat[(dat[correlation_column] >= 0) & (dat['Coexist'] == 1)])\n",
    "    proportions[f'positive_exclusion_{correlation_column}'] = len(dat[(dat[correlation_column] >= 0) & (dat['Coexist'] == 0)])\n",
    "    proportions[f'negative_coexistence_{correlation_column}'] = len(dat[(dat[correlation_column] < 0) & (dat['Coexist'] == 1)])\n",
    "    proportions[f'negative_exclusion_{correlation_column}'] = len(dat[(dat[correlation_column] < 0) & (dat['Coexist'] == 0)])\n",
    "    return proportions\n",
    "\n",
    "def report_coexistence_analysis(proportions, correlation_column):\n",
    "    positive_key = f'positive_coexistence_{correlation_column}'\n",
    "    negative_key = f'negative_coexistence_{correlation_column}'\n",
    "    positive_excl_key = f'positive_exclusion_{correlation_column}'\n",
    "    negative_excl_key = f'negative_exclusion_{correlation_column}'\n",
    "    pos_total = proportions[positive_key] + proportions[positive_excl_key]\n",
    "    neg_total = proportions[negative_key] + proportions[negative_excl_key]\n",
    "    neg_confint = proportion_confint(count=proportions[negative_key], nobs=neg_total, alpha=0.05, method='wilson')\n",
    "    pos_confint = proportion_confint(count=proportions[positive_key], nobs=pos_total, alpha=0.05, method='wilson')\n",
    "    print(f\"\\nAnalysis on Negative \\u03BD for {correlation_column.upper()}:\")\n",
    "    print(f\"Proportion of coexistence with \\u03BD \\u2265 0: {proportions[positive_key] / pos_total:.2g} (95% CI: ({pos_confint[0]:.2g}, {pos_confint[1]:.2g}))\")\n",
    "    print(f\"Proportion of coexistence with \\u03BD < 0: {proportions[negative_key] / neg_total:.2g} (95% CI: ({neg_confint[0]:.2g}, {neg_confint[1]:.2g}))\")\n",
    "\n",
    "def analyze_coexistence_effect(data):\n",
    "    models_results = {}\n",
    "    correlation_column = 'cor_sos'\n",
    "    analysis_type = 'SoS'\n",
    "    if correlation_column not in data.columns:\n",
    "        return models_results\n",
    "    print(f\"\\n--- Analysis for {analysis_type} ---\")\n",
    "    intercept, coef, std_err, z_scores, p_values = perform_logistic_regression(data, analysis_type)\n",
    "    models_results[analysis_type] = {\n",
    "        'statsmodels': (intercept, coef, std_err, z_scores, p_values),\n",
    "    }\n",
    "    proportions = calculate_proportions(data, correlation_column)\n",
    "    report_coexistence_analysis(proportions, correlation_column)\n",
    "    table_data = {\n",
    "        '\\u03BD \\u2265 0': [proportions[f'positive_coexistence_{correlation_column}'], proportions[f'positive_exclusion_{correlation_column}']],\n",
    "        '\\u03BD < 0': [proportions[f'negative_coexistence_{correlation_column}'], proportions[f'negative_exclusion_{correlation_column}']]\n",
    "    }\n",
    "    table_df = pd.DataFrame(table_data, index=['Coexistence', 'Exclusion'])\n",
    "    print(f\"Coexistence and Exclusion based on \\u03BD for {analysis_type}:\\n\", table_df)\n",
    "    # Confidence intervals\n",
    "    pos_total = proportions[f'positive_coexistence_{correlation_column}'] + proportions[f'positive_exclusion_{correlation_column}']\n",
    "    neg_total = proportions[f'negative_coexistence_{correlation_column}'] + proportions[f'negative_exclusion_{correlation_column}']\n",
    "    pos_confint = proportion_confint(count=proportions[f'positive_coexistence_{correlation_column}'], nobs=pos_total, alpha=0.05, method='wilson')\n",
    "    neg_confint = proportion_confint(count=proportions[f'negative_coexistence_{correlation_column}'], nobs=neg_total, alpha=0.05, method='wilson')\n",
    "    # Decision logic\n",
    "    if neg_confint[1] >= pos_confint[0] and neg_confint[0] <= pos_confint[1]:\n",
    "        print(f\"The confidence intervals overlap for {analysis_type}, indicating they are statistically the same, not supporting the authors' results.\")\n",
    "    elif neg_confint[1] > pos_confint[0]:\n",
    "        print(f\"Higher coexistence observed with \\u03BD < 0 for {analysis_type}, supporting the authors' results.\")\n",
    "    else:\n",
    "        print(f\"Higher coexistence observed with \\u03BD \\u2265 0 for {analysis_type}, not supporting the authors' results.\")\n",
    "    return models_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_phase_plane():\n",
    "    # Parameters for each scenario\n",
    "    scenarios = {\n",
    "        \"A: $E_1 > Q$ and $P > E_2$\": {'r1': 18, 'r2': 16, 'a11': 0.5, 'a12': 1, 'a21': 1, 'a22': 1},\n",
    "        \"B: $Q > E_1$ and $E_2 > P$\": {'r1': 20, 'r2': 15, 'a11': 2, 'a12': 1, 'a21': 1, 'a22': 0.5},\n",
    "        \"C: $Q > E_1$ and $P > E_2$\":  {'r1': 20, 'r2': 15, 'a11': 3, 'a12': 0.5, 'a21': 1, 'a22': 0.5},\n",
    "        \"D: $E_1 > Q$ and $E_2 > P$\":  {'r1': 16, 'r2': 18, 'a11': 0.3, 'a12': 1, 'a21': 1, 'a22': 0.5},\n",
    "    }    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    axes = axes.flatten()    \n",
    "    for i, (title, params) in enumerate(scenarios.items()):\n",
    "        ax = axes[i]\n",
    "        # Unpack parameters\n",
    "        r1 = params['r1']\n",
    "        r2 = params['r2']\n",
    "        a11 = params['a11']\n",
    "        a12 = params['a12']\n",
    "        a21 = params['a21']\n",
    "        a22 = params['a22']\n",
    "        # Equilibrium points\n",
    "        E1 = [(r1 - 1) / a11, 0]\n",
    "        Q = [(r2 - 1) / a21, 0]\n",
    "        E2 = [0, (r2 - 1) / a22]\n",
    "        P = [0, (r1 - 1) / a12]\n",
    "        E0 = [0, 0]\n",
    "        # Calculate the intersection point of lines (E1, Q) and (E2, P)\n",
    "        a1 = (P[1] - E1[1]) / (P[0] - E1[0]) if P[0] != E1[0] else float('inf')\n",
    "        b1 = E1[1] - a1 * E1[0]\n",
    "        a2 = (E2[1] - Q[1]) / (E2[0] - Q[0]) if E2[0] != Q[0] else float('inf')\n",
    "        b2 = Q[1] - a2 * Q[0]\n",
    "        if a1 != a2:  # Ensure lines are not parallel\n",
    "            E3_x = (b2 - b1) / (a1 - a2) if a1 != float('inf') and a2 != float('inf') else 0\n",
    "            E3_y = a1 * E3_x + b1 if a1 != float('inf') else a2 * E3_x + b2\n",
    "            E3 = [E3_x, E3_y]\n",
    "        else:\n",
    "            E3 = None\n",
    "        # Extend axis limits by 10%\n",
    "        max_N1 = max(E1[0], Q[0])\n",
    "        max_N2 = max(E2[1], P[1])\n",
    "        N1 = np.linspace(0, max_N1, 30)\n",
    "        N2 = np.linspace(0, max_N2, 30)\n",
    "        N1, N2 = np.meshgrid(N1, N2)\n",
    "        # Compute the discrete system\n",
    "        N1_next = r1 * N1 / (1 + a11 * N1 + a12 * N2)\n",
    "        N2_next = r2 * N2 / (1 + a22 * N2 + a21 * N1)\n",
    "        # Plot vector field\n",
    "        ax.quiver(N1, N2, N1_next - N1, N2_next - N2, angles='xy', scale_units='xy', scale=15, color='grey', alpha=1)\n",
    "        # Plot equilibrium points\n",
    "        ax.plot(E0[0], E0[1], 'ko', label='E0', markersize=8)\n",
    "        ax.plot(E1[0], E1[1], 'bo', label='E1', markersize=8)\n",
    "        ax.plot(Q[0], Q[1], 'ro', label='Q', markersize=8)\n",
    "        ax.plot(E2[0], E2[1], 'ro', label='E2', markersize=8)\n",
    "        ax.plot(P[0], P[1], 'bo', label='P', markersize=8)\n",
    "        # Draw lines between points\n",
    "        ax.plot([E1[0], P[0]], [E1[1], P[1]], 'b-', lw=2)  # Line between P and E1 (blue)\n",
    "        ax.plot([Q[0], E2[0]], [Q[1], E2[1]], 'r-', lw=2)  # Line between Q and E2 (red)\n",
    "        # Plot intersection point E3 if it exists within the plot limits and above the lines\n",
    "        if E3 is not None and (0 <= E3[0] <= 1.1 * max_N1) and (0 <= E3[1] <= 1.1 * max_N2):\n",
    "            ax.plot(E3[0], E3[1], 'go', label=r'$E_3$', markersize=8)\n",
    "            # Annotate E3 near the point\n",
    "            ax.annotate(f'$E_3$', xy=(E3[0], E3[1]), xytext=(E3[0] + 0.3, E3[1] + 0.3), fontsize=18, color='green')\n",
    "        # Set labels and title\n",
    "        ax.set_xlabel(r'$N_1$', fontsize=18)\n",
    "        ax.set_ylabel(r'$N_2$', fontsize=18)\n",
    "        # Move title to the left\n",
    "        ax.set_title(title, fontsize=18, loc='left')\n",
    "        # Set xticks and yticks with labels for E1, E2, P, Q\n",
    "        ax.set_xticks([0, E1[0], Q[0]])\n",
    "        ax.set_xticklabels([r'$E_0$', r'$E_1$', r'$Q$'])\n",
    "        ax.set_yticks([0, E2[1], P[1]])\n",
    "        ax.set_yticklabels([r'$E_0$', r'$E_2$', r'$P$'])\n",
    "        ax.tick_params(axis='both', which='major', labelsize=18)\n",
    "    # Adjust layout and save the figure\n",
    "    plt.tight_layout()\n",
    "    os.makedirs('img', exist_ok=True)\n",
    "    plt.savefig('img/phase_plane.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_pipeline(filters, base_file, truncate, extinc_crit_1):\n",
    "    os.makedirs('csv', exist_ok=True)\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    print(\"Running simulation...\")\n",
    "    mesh = preprocess_data('table1')\n",
    "    results = [Sim(k, row, extinc_crit_1=extinc_crit_1)\n",
    "                for k, row in tqdm(enumerate(mesh), total=len(mesh))]\n",
    "    postprocess_results(results, base_file)\n",
    "    for filter_option in filters:\n",
    "        filtered_filename = f\"csv/annplant_2spp_det_rare_filtered_{filter_option}.csv\"\n",
    "        print(f\"\\nGenerating data for filter={filter_option}...\")\n",
    "        cor_figure(filter_option, truncate)\n",
    "        summary_path = f\"csv/pgr_analysis_summary_{filter_option}.csv\"\n",
    "        filtered_data = pd.read_csv(filtered_filename)\n",
    "        analyze_coexistence_effect(filtered_data)\n",
    "        plot_phase_plane()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    filters = ['on', 'off']\n",
    "    base_file = \"csv/annplant_2spp_det_rare.csv\"\n",
    "    # truncate, extinc_crit_1 = True, True # Yenni et al. (2012) truncate the values and consider extinction N<1\n",
    "    truncate, extinc_crit_1 = False, True # the numerical results are slightly different if not truncated\n",
    "    # truncate, extinc_crit_1 = False, False # the numerical results are slightly different if not truncated and extinction N<0\n",
    "    setup_pipeline(filters, base_file, truncate, extinc_crit_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running simulation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 77760/77760 [00:11<00:00, 6605.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating data for filter=on...\n",
      "\n",
      "--- Analysis for SoS ---\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                Coexist   No. Observations:                18001\n",
      "Model:                            GLM   Df Residuals:                    17997\n",
      "Model Family:                Binomial   Df Model:                            3\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -3477.6\n",
      "Date:                Wed, 02 Jul 2025   Deviance:                       6955.3\n",
      "Time:                        11:36:42   Pearson chi2:                 2.78e+04\n",
      "No. Iterations:                    10   Pseudo R-squ. (CS):             0.6130\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const        -42.4184      0.787    -53.898      0.000     -43.961     -40.876\n",
      "S1            17.4522      0.350     49.795      0.000      16.765      18.139\n",
      "FE1           23.8388      0.470     50.718      0.000      22.918      24.760\n",
      "cor_sos       -0.0065      0.000    -15.071      0.000      -0.007      -0.006\n",
      "==============================================================================\n",
      "\n",
      "Analysis on Negative ν for COR_SOS:\n",
      "Proportion of coexistence with ν ≥ 0: 0.59 (95% CI: (0.58, 0.59))\n",
      "Proportion of coexistence with ν < 0: 0.93 (95% CI: (0.92, 0.95))\n",
      "Coexistence and Exclusion based on ν for SoS:\n",
      "              ν ≥ 0  ν < 0\n",
      "Coexistence   9775   1242\n",
      "Exclusion     6896     88\n",
      "Higher coexistence observed with ν < 0 for SoS, supporting the authors' results.\n",
      "\n",
      "Generating data for filter=off...\n",
      "\n",
      "--- Analysis for SoS ---\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                Coexist   No. Observations:                39203\n",
      "Model:                            GLM   Df Residuals:                    39199\n",
      "Model Family:                Binomial   Df Model:                            3\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -19965.\n",
      "Date:                Wed, 02 Jul 2025   Deviance:                       39930.\n",
      "Time:                        11:36:43   Pearson chi2:                 1.10e+05\n",
      "No. Iterations:                     6   Pseudo R-squ. (CS):             0.2264\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -4.9200      0.102    -48.082      0.000      -5.121      -4.719\n",
      "S1             1.5394      0.024     64.251      0.000       1.492       1.586\n",
      "FE1            2.4742      0.090     27.479      0.000       2.298       2.651\n",
      "cor_sos       -0.0021      0.000    -13.313      0.000      -0.002      -0.002\n",
      "==============================================================================\n",
      "\n",
      "Analysis on Negative ν for COR_SOS:\n",
      "Proportion of coexistence with ν ≥ 0: 0.33 (95% CI: (0.33, 0.34))\n",
      "Proportion of coexistence with ν < 0: 0.35 (95% CI: (0.34, 0.36))\n",
      "Coexistence and Exclusion based on ν for SoS:\n",
      "              ν ≥ 0  ν < 0\n",
      "Coexistence  10034   3097\n",
      "Exclusion    20200   5872\n",
      "The confidence intervals overlap for SoS, indicating they are statistically the same, not supporting the authors' results.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
