{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The code aims to modify the analysis of Yenni et al. (2012):\n",
    "#### - corrected the SoS calculation\n",
    "#### - modified the parameters to paper's description: \"r2 integers from 11 to 20\"\n",
    "#### - removed the additional filter S1 >= 1 & S2 >= 1\n",
    "#### - did not truncate the values\n",
    "#### - included additional metrics: CA and CE\n",
    "\n",
    "#### their original code: https://github.com/gmyenni/RareStabilizationSimulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.special import expit\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analyN_function.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyN(r1, r2, a1, a12, a21, a2):\n",
    "    N1 = (r1 - 1 - (a12 / a2) * (r2 - 1)) / (a1 - a21 * a12 / a2)\n",
    "    N2 = (r2 - 1 - (a21 / a1) * (r1 - 1)) / (a2 - a21 * a12 / a1)\n",
    "    \n",
    "    if np.isinf(N1) or np.isinf(N2) or np.isnan(N1) or np.isnan(N2):\n",
    "        initialNsp1 = 0\n",
    "        initialNsp2 = 0\n",
    "        N = np.zeros((100, 2))\n",
    "        N[0, :] = [initialNsp1, initialNsp2]\n",
    "        \n",
    "        for i in range(1, 100):\n",
    "            N[i, 0] = max((r1 - 1 - a12 * N[i-1, 1]) / a1, 0)\n",
    "            N[i, 1] = max((r2 - 1 - a21 * N[i-1, 0]) / a2, 0)\n",
    "        \n",
    "        N1 = np.mean(N[:, 0])\n",
    "        N2 = np.mean(N[:, 1])\n",
    "    \n",
    "    if N1 < 0 and N2 >= 0:\n",
    "        N1 = 0\n",
    "        N2 = (r2 - 1) / a2\n",
    "    elif N2 < 0 and N1 >= 0:\n",
    "        N2 = 0\n",
    "        N1 = (r1 - 1) / a1\n",
    "    \n",
    "    return N1, N2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# getNFD.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(l1, l2, a11, a12, a21, a22, N1, N2):\n",
    "    CoexistRank = 0 if N1 < 1 else 1\n",
    "\n",
    "#     The original code of Yenni et al. replaced l1 with l2 in the numerator:\n",
    "#     S1 = l2 / (1 + (a12 / a22) * (l2 - 1))\n",
    "#     S2 = l1 / (1 + (a21 / a11) * (l1 - 1))\n",
    "#     # Corrected Strength of Stabilization:\n",
    "    S1 = l1 / (1 + (a12 / a22) * (l2 - 1))\n",
    "    S2 = l2 / (1 + (a21 / a11) * (l1 - 1))\n",
    "\n",
    "    # Fitness equivalence\n",
    "    E1, E2 = l1 / l2, l2 / l1\n",
    "\n",
    "    # Asymmetry between the species\n",
    "    Asy = S1 - S2\n",
    "\n",
    "    # Calculation for the rare species\n",
    "    Rare = 0 if N1 == 0 and N2 == 0 else N1 / (N1 + N2)\n",
    "\n",
    "    # Competitive Ability and Efficiency calculations\n",
    "    CA1, CA2 = competitive_ability(l1, l2, a11, a22, a12, a21)\n",
    "    CE1, CE2, CE_status = competitive_efficiency(l1, l2, a11, a22, a12, a21)\n",
    "\n",
    "    # Array for abundance\n",
    "    x = np.array([N1, N2])\n",
    "    \n",
    "    # Covariances calculations\n",
    "    y_sos = np.array([S1, S2])\n",
    "    cor_sos = np.cov(x, y_sos)[0, 1]  # Covariance for SoS\n",
    "    \n",
    "    y_ca = np.array([CA1, CA2])\n",
    "    cor_ca = np.cov(x, y_ca)[0, 1]  # Covariance for CA\n",
    "\n",
    "    y_ce = np.array([CE1, CE2])\n",
    "    cor_ce = np.cov(x, y_ce)[0, 1]  # Covariance for CE\n",
    "\n",
    "    CE_status_map = {'global_competitive_exclusion': 1, 'local_coexistence': 2, 'global_coexistence': 3, 'local_competitive_exclusion': 4}\n",
    "    CE_status_num = CE_status_map[CE_status]\n",
    "    \n",
    "    Rank = 0 if N1 == 0 and N2 == 0 else (2 if N1 / (N1 + N2) <= 0.25 else 1)\n",
    "    \n",
    "    metrics = [CoexistRank, E1, S1, E2, S2, Asy, cor_sos, Rare, Rank, CA1, CA2, CE1, CE2, CE_status_num, cor_ca, cor_ce]\n",
    "    return np.array(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional competitive metrics:\n",
    "### - Competitive Ability CA Hart et al. (2018)\n",
    "### - Competitive Efficiency CE Streipert and Wolkowicz (2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def competitive_ability(r1, r2, a11, a22, a12, a21):\n",
    "    CA1 = (r1 - 1) / np.sqrt(a12 * a11)\n",
    "    CA2 = (r2 - 1) / np.sqrt(a21 * a22)\n",
    "    return CA1, CA2\n",
    "\n",
    "def competitive_efficiency(r1, r2, a11, a22, a12, a21):\n",
    "    tolerance = 1e-9\n",
    "    CE1 = ((r1 - 1) / a12) - ((r2 - 1) / a22)\n",
    "    CE2 = ((r2 - 1) / a21) - ((r1 - 1) / a11)\n",
    "    if abs(CE1) <= tolerance and abs(CE2) <= tolerance:\n",
    "        return CE1, CE2, 'local_coexistence'\n",
    "    elif CE1 * CE2 < 0 or (abs(CE1) <= tolerance and abs(CE2) >= tolerance) or (abs(CE2) <= tolerance and abs(CE1) >= tolerance):\n",
    "        return CE1, CE2, 'global_competitive_exclusion'\n",
    "    elif CE1 < 0 and CE2 < 0:\n",
    "        return CE1, CE2, 'local_competitive_exclusion'\n",
    "    elif CE1 > 0 and CE2 > 0:\n",
    "        return CE1, CE2, 'global_coexistence'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# annualplant_2spp_det_par.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-22 14:56:38.609773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_137388/3128295576.py:2: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  N1 = (r1 - 1 - (a12 / a2) * (r2 - 1)) / (a1 - a21 * a12 / a2)\n",
      "/tmp/ipykernel_137388/3128295576.py:3: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  N2 = (r2 - 1 - (a21 / a1) * (r1 - 1)) / (a2 - a21 * a12 / a1)\n",
      "/tmp/ipykernel_137388/3128295576.py:2: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  N1 = (r1 - 1 - (a12 / a2) * (r2 - 1)) / (a1 - a21 * a12 / a2)\n",
      "/tmp/ipykernel_137388/3128295576.py:3: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  N2 = (r2 - 1 - (a21 / a1) * (r1 - 1)) / (a2 - a21 * a12 / a1)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data():\n",
    "    # Defines frequency-dependent parameters\n",
    "#     l1_v = np.arange(15, 21)\n",
    "#     l2_v = np.arange(15, 21)\n",
    "    a11_v = np.array([0.1, 0.3, 0.5, 0.7, 0.9, 1, 1.5, 2, 2.5, 3])\n",
    "    a12_v = np.array([0.1, 0.3, 0.5, 0.7, 0.9, 1])\n",
    "    a21_v = np.array([0.1, 0.3, 0.5, 0.7, 0.9, 1])\n",
    "    a22_v = np.array([0.1, 0.3, 0.5, 0.7, 0.9, 1])\n",
    "    l1_v = np.arange(15, 21)\n",
    "    l2_v = np.arange(11, 21)\n",
    "#     a11_v = np.arange(0.7, 3,0.1)\n",
    "#     a12_v = np.arange(0.1, 1,0.1)\n",
    "#     a21_v = np.arange(0.1, 1,0.1)\n",
    "#     a22_v = np.arange(0.1, 1,0.1)\n",
    "\n",
    "    # Generate all combinations of parameters using NumPy's meshgrid\n",
    "    mesh = np.array(np.meshgrid(l1_v, l2_v, a11_v, a12_v, a21_v, a22_v)).T.reshape(-1, 6)\n",
    "    return mesh\n",
    "\n",
    "def Sim(k, mesh_row):\n",
    "    l1, l2, a11, a12, a21, a22 = mesh_row\n",
    "    # Simulate and calculate additional metrics based on the parameters\n",
    "    N1, N2 = analyN(l1, l2, a11, a12, a21, a22)\n",
    "    metrics = calculate_metrics(l1, l2, a11, a12, a21, a22, N1, N2)\n",
    "    CoexistRank, E1, S1, E2, S2, Asy, cor_sos, Rare, Rank, CA1, CA2, CE1, CE2, CE_status_num, cor_ca, cor_ce = metrics    \n",
    "    return np.array([l1, l2, a11, a12, a21, a22, N1, N2, E1, E2, S1, S2, Rank, CoexistRank, Asy, cor_sos, Rare, CA1, CA2, CE1, CE2, CE_status_num, cor_ca, cor_ce])\n",
    "\n",
    "def postprocess_results(results, outfile):\n",
    "    column_order = ['l1', 'l2', 'a11', 'a12', 'a21', 'a22', 'N1', 'N2', 'E1', 'S1', 'E2', 'S2', 'Rank', 'CoexistRank', 'Asy', 'cor_sos', 'Rare', 'CA1', 'CA2', 'CE1', 'CE2', 'CE_status', 'cor_ca', 'cor_ce']\n",
    "    simul = pd.DataFrame(results, columns=column_order)\n",
    "    simul.to_csv(outfile, index=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(datetime.now())\n",
    "    outfile = \"csv/annplant_2spp_det_rare.csv\"\n",
    "    mesh = preprocess_data()\n",
    "    column_order = ['l1', 'l2', 'a11', 'a12', 'a21', 'a22', 'N1', 'N2', 'S1', 'S2', 'E1', 'E2', 'CA1', 'CA2', 'CE1', 'CE2', 'CE_status', 'Rank', 'CoexistRank', 'Asy', 'Rare', 'cor_sos', 'cor_ca', 'cor_ce']\n",
    "    results = np.empty((len(mesh), len(column_order)), dtype=float)\n",
    "    # Run the simulation for each row in the parameter combination mesh\n",
    "    for k in range(len(mesh)):\n",
    "        results[k] = Sim(k, mesh[k])\n",
    "    postprocess_results(results, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cor_figure.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cor_figure():\n",
    "    dat_det = pd.read_csv(\"csv/annplant_2spp_det_rare.csv\")\n",
    "    dat_det = dat_det.query('Rank == 2').copy() # Apply filter  & S1 >= 1 & S2 >= 1\n",
    "    dat_det.reset_index(drop=True, inplace=True)\n",
    "#     dat_det = np.trunc(dat_det * 100) / 100.0  # Truncate to two decimals\n",
    "    dat_det.sort_values(by=['a22', 'a21', 'a12', 'a11', 'l2', 'l1'], inplace=True)\n",
    "    dat_det.to_csv(\"csv/annplant_2spp_det_rare_filtered.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_summarize_model(X, y):\n",
    "    model = sm.GLM(y, X, family=sm.families.Binomial())\n",
    "    result = model.fit()\n",
    "    n = len(y)  # Sample size\n",
    "    k = X.shape[1] - 1  # Number of parameters, excluding the constant\n",
    "    aic = result.aic\n",
    "    bic = result.bic\n",
    "    aicc = aic + (2 * k * (k + 1)) / (n - k - 1)  # Corrected AIC for small sample sizes\n",
    "    return aic, aicc, bic, result\n",
    "\n",
    "def compute_weights(criterion_values):\n",
    "    min_value = np.min(criterion_values)\n",
    "    delta_values = criterion_values - min_value\n",
    "    relative_likelihoods = np.exp(-0.5 * delta_values)\n",
    "    sum_likelihoods = np.sum(relative_likelihoods)\n",
    "    weights = relative_likelihoods / sum_likelihoods\n",
    "    return weights\n",
    "\n",
    "def apply_pca_to_pairs(dat, pairs):\n",
    "    scaler = StandardScaler()  # Standardizing the features\n",
    "    for pair in pairs:\n",
    "        sub_X = dat[list(pair)].copy()\n",
    "        sub_X_scaled = scaler.fit_transform(sub_X)  # Standardize the data before applying PCA\n",
    "        pca = PCA(n_components=1)\n",
    "        X_pca = pca.fit_transform(sub_X_scaled)\n",
    "        explained_variance = pca.explained_variance_ratio_[0]  # Get the explained variance\n",
    "        print(f\"PCA applied for {pair}.\")\n",
    "        print(f\"Explained Variance: {explained_variance}\")  # Print the explained variance\n",
    "        pca_col_name = f\"{pair[0]}_{pair[1]}_PCA\"\n",
    "        dat[pca_col_name] = X_pca\n",
    "        dat.drop(list(pair), axis=1, inplace=True)\n",
    "    return dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# figures_det.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_coexistence_effect(file_path):\n",
    "    dat = pd.read_csv(file_path)\n",
    "    \n",
    "    # Applying PCA to specified pairs\n",
    "    pairs_to_check = [('S1', 'S2'), ('E1', 'E2'), ('CA1', 'CA2'), ('CE1', 'CE2')]\n",
    "    dat = apply_pca_to_pairs(dat, pairs_to_check)\n",
    "\n",
    "    # Prepare data for each model\n",
    "    X_sos = sm.add_constant(dat[['S1_S2_PCA', 'E1_E2_PCA', 'cor_sos']])\n",
    "    X_ca = sm.add_constant(dat[['CA1_CA2_PCA', 'cor_ca']])\n",
    "    X_ce = sm.add_constant(dat[['CE1_CE2_PCA', 'cor_ce']])\n",
    "\n",
    "    models = {'SoS': X_sos, 'CA': X_ca, 'CE': X_ce}\n",
    "    criterion_values = {'AIC': [], 'AICc': [], 'BIC': []}\n",
    "    fitted_models = {}\n",
    "\n",
    "    # Fit models and calculate criterion values\n",
    "    for name, X in models.items():\n",
    "        model = sm.GLM(dat['CoexistRank'], X, family=sm.families.Binomial())\n",
    "        fitted_model = model.fit()\n",
    "        n = len(dat['CoexistRank'])  # Sample size\n",
    "        k = X.shape[1] - 1  # Number of parameters, excluding the constant\n",
    "        aic = fitted_model.aic\n",
    "        bic = fitted_model.bic\n",
    "        aicc = aic + (2 * k * (k + 1)) / (n - k - 1)  # Corrected AIC for small sample sizes\n",
    "        criterion_values['AIC'].append(aic)\n",
    "        criterion_values['AICc'].append(aicc)\n",
    "        criterion_values['BIC'].append(bic)\n",
    "        fitted_models[name] = fitted_model\n",
    "\n",
    "    # Display raw AIC, AICc, and BIC values in a table\n",
    "    print(\"\\nCriterion Values:\")\n",
    "    criterion_df = pd.DataFrame(criterion_values, index=models.keys())\n",
    "    print(criterion_df)\n",
    "\n",
    "    # Compute weights for AIC, AICc, and BIC\n",
    "    aic_weights = compute_weights(np.array(criterion_values['AIC']))\n",
    "    aicc_weights = compute_weights(np.array(criterion_values['AICc']))\n",
    "    bic_weights = compute_weights(np.array(criterion_values['BIC']))\n",
    "\n",
    "    # Display the weights in a separate table\n",
    "    print(\"\\nModel Weights:\")\n",
    "    weights_df = pd.DataFrame({\n",
    "        'AIC Weight': aic_weights,\n",
    "        'AICc Weight': aicc_weights,\n",
    "        'BIC Weight': bic_weights\n",
    "    }, index=models.keys())\n",
    "    print(weights_df)\n",
    "\n",
    "    for name, model in fitted_models.items():\n",
    "        print(f\"{name} Model Summary:\\n{model.summary()}\\n\")\n",
    "\n",
    "def perform_proportion_analysis(dat, cor_column, metric_name):\n",
    "    negative_nu = dat[dat[cor_column] < 0]\n",
    "    non_negative_nu = dat[dat[cor_column] >= 0]\n",
    "    negative_nu_coexist = negative_nu[negative_nu['CoexistRank'] == 1]\n",
    "    non_negative_nu_coexist = non_negative_nu[non_negative_nu['CoexistRank'] == 1]\n",
    "\n",
    "    # Counting coexistence and exclusion\n",
    "    nu_positive_coexistence = len(non_negative_nu_coexist)\n",
    "    nu_positive_exclusion = len(non_negative_nu) - nu_positive_coexistence\n",
    "    nu_negative_coexistence = len(negative_nu_coexist)\n",
    "    nu_negative_exclusion = len(negative_nu) - nu_negative_coexistence\n",
    "\n",
    "    # Display the table\n",
    "    table_data = {\n",
    "        f'\\u03BD_{metric_name} \\u2265 0': [nu_positive_coexistence, nu_positive_exclusion],\n",
    "        f'\\u03BD_{metric_name} < 0': [nu_negative_coexistence, nu_negative_exclusion]\n",
    "    }\n",
    "    table_df = pd.DataFrame(table_data, index=['coexistence', 'exclusion'])\n",
    "    print(\"\\nCoexistence and Exclusion based on \\u03BD:\\n\", table_df)\n",
    "\n",
    "    proportion_negative_nu = len(negative_nu_coexist) / len(negative_nu) if len(negative_nu) > 0 else 0\n",
    "    proportion_non_negative_nu = len(non_negative_nu_coexist) / len(non_negative_nu) if len(non_negative_nu) > 0 else 0\n",
    "\n",
    "    neg_nu_confint = proportion_confint(count=len(negative_nu_coexist), nobs=len(negative_nu), alpha=0.05, method='wilson')\n",
    "    non_neg_nu_confint = proportion_confint(count=len(non_negative_nu_coexist), nobs=len(non_negative_nu), alpha=0.05, method='wilson')\n",
    "\n",
    "    print(f\"\\nAnalysis on Negative \\u03BD for {metric_name}:\")\n",
    "    print(f\"Proportion of coexistence with \\u03BD_{metric_name} < 0: {proportion_negative_nu:.4f} (95% CI: {neg_nu_confint})\")\n",
    "    print(f\"Proportion of coexistence with \\u03BD_{metric_name} \\u2265 0: {proportion_non_negative_nu:.4f} (95% CI: {non_neg_nu_confint})\")\n",
    "\n",
    "    if neg_nu_confint[1] < non_neg_nu_confint[0]:\n",
    "        print(f\"Higher coexistence observed with \\u03BD \\u2265 0 for {metric_name}, not supporting the authors' claim that 'coexistence is predicted more often when \\u03BD is negative'.\")\n",
    "    elif neg_nu_confint[0] > non_neg_nu_confint[1]:\n",
    "        print(f\"Higher coexistence observed with \\u03BD < 0 for {metric_name}, supporting the authors' claim that 'coexistence is predicted more often when \\u03BD is negative'.\")\n",
    "    else:\n",
    "        print(f\"Confidence intervals for proportions overlap for {metric_name}, suggesting the effect of \\u03BD on coexistence is inconclusive.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA applied for ('S1', 'S2').\n",
      "Explained Variance: 0.6319420437828324\n",
      "PCA applied for ('E1', 'E2').\n",
      "Explained Variance: 0.549857605350732\n",
      "PCA applied for ('CA1', 'CA2').\n",
      "Explained Variance: 0.5137053877160738\n",
      "PCA applied for ('CE1', 'CE2').\n",
      "Explained Variance: 0.6041981567626186\n",
      "\n",
      "Criterion Values:\n",
      "              AIC          AICc            BIC\n",
      "SoS  67192.628807  67192.629203 -601603.190278\n",
      "CA   75323.688800  75323.688998 -593481.144396\n",
      "CE   75434.779155  75434.779353 -593370.054041\n",
      "\n",
      "Model Weights:\n",
      "     AIC Weight  AICc Weight  BIC Weight\n",
      "SoS         1.0          1.0         1.0\n",
      "CA          0.0          0.0         0.0\n",
      "CE          0.0          0.0         0.0\n",
      "SoS Model Summary:\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:            CoexistRank   No. Observations:                60725\n",
      "Model:                            GLM   Df Residuals:                    60721\n",
      "Model Family:                Binomial   Df Model:                            3\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -33592.\n",
      "Date:                Fri, 22 Mar 2024   Deviance:                       67185.\n",
      "Time:                        14:57:12   Pearson chi2:                 6.86e+04\n",
      "No. Iterations:                     6   Pseudo R-squ. (CS):             0.1681\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.2791      0.011    -24.518      0.000      -0.301      -0.257\n",
      "S1_S2_PCA      0.9274      0.014     68.538      0.000       0.901       0.954\n",
      "E1_E2_PCA      0.9586      0.014     70.913      0.000       0.932       0.985\n",
      "cor_sos       -0.0099      0.000    -44.248      0.000      -0.010      -0.009\n",
      "==============================================================================\n",
      "\n",
      "CA Model Summary:\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:            CoexistRank   No. Observations:                60725\n",
      "Model:                            GLM   Df Residuals:                    60722\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -37659.\n",
      "Date:                Fri, 22 Mar 2024   Deviance:                       75318.\n",
      "Time:                        14:57:12   Pearson chi2:                 6.06e+04\n",
      "No. Iterations:                     6   Pseudo R-squ. (CS):            0.04890\n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "const          -0.4246      0.009    -44.927      0.000      -0.443      -0.406\n",
      "CA1_CA2_PCA    -0.5615      0.016    -34.764      0.000      -0.593      -0.530\n",
      "cor_ca         -0.0005   1.26e-05    -40.312      0.000      -0.001      -0.000\n",
      "===============================================================================\n",
      "\n",
      "CE Model Summary:\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:            CoexistRank   No. Observations:                60725\n",
      "Model:                            GLM   Df Residuals:                    60722\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -37714.\n",
      "Date:                Fri, 22 Mar 2024   Deviance:                       75429.\n",
      "Time:                        14:57:12   Pearson chi2:                 5.85e+04\n",
      "No. Iterations:                     6   Pseudo R-squ. (CS):            0.04715\n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "const          -0.5428      0.010    -57.034      0.000      -0.561      -0.524\n",
      "CE1_CE2_PCA     0.0460      0.014      3.331      0.001       0.019       0.073\n",
      "cor_ce         -0.0002   6.11e-06    -25.283      0.000      -0.000      -0.000\n",
      "===============================================================================\n",
      "\n",
      "\n",
      "Coexistence and Exclusion based on ν:\n",
      "              ν_SoS ≥ 0  ν_SoS < 0\n",
      "coexistence      16100       4938\n",
      "exclusion        27248      12439\n",
      "\n",
      "Analysis on Negative ν for SoS:\n",
      "Proportion of coexistence with ν_SoS < 0: 0.2842 (95% CI: (0.27751114742186744, 0.29092171483214735))\n",
      "Proportion of coexistence with ν_SoS ≥ 0: 0.3714 (95% CI: (0.3668757655545365, 0.37597252820042826))\n",
      "Higher coexistence observed with ν ≥ 0 for SoS, not supporting the authors' claim that 'coexistence is predicted more often when ν is negative'.\n",
      "\n",
      "Coexistence and Exclusion based on ν:\n",
      "              ν_CA ≥ 0  ν_CA < 0\n",
      "coexistence     16129      4909\n",
      "exclusion       27248     12439\n",
      "\n",
      "Analysis on Negative ν for CA:\n",
      "Proportion of coexistence with ν_CA < 0: 0.2830 (95% CI: (0.2763178098906173, 0.28972248514837556))\n",
      "Proportion of coexistence with ν_CA ≥ 0: 0.3718 (95% CI: (0.3672964372426985, 0.37639225974685336))\n",
      "Higher coexistence observed with ν ≥ 0 for CA, not supporting the authors' claim that 'coexistence is predicted more often when ν is negative'.\n",
      "\n",
      "Coexistence and Exclusion based on ν:\n",
      "              ν_CE ≥ 0  ν_CE < 0\n",
      "coexistence     12504      8534\n",
      "exclusion       27219     12468\n",
      "\n",
      "Analysis on Negative ν for CE:\n",
      "Proportion of coexistence with ν_CE < 0: 0.4063 (95% CI: (0.39971746214954984, 0.4130012995476613))\n",
      "Proportion of coexistence with ν_CE ≥ 0: 0.3148 (95% CI: (0.3102307929930779, 0.31936472833088647))\n",
      "Higher coexistence observed with ν < 0 for CE, supporting the authors' claim that 'coexistence is predicted more often when ν is negative'.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Suppress warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    # Generate simulation results\n",
    "    output_file = \"csv/annplant_2spp_det_rare_filtered.csv\"\n",
    "    data_grid = preprocess_data()\n",
    "    simulations = np.array([Sim(k, row) for k, row in enumerate(data_grid)])\n",
    "    postprocess_results(simulations, output_file)\n",
    "\n",
    "    cor_figure() # apply filters\n",
    "\n",
    "    dat = pd.read_csv(output_file)  # Load the simulation results\n",
    "    analyze_coexistence_effect(output_file)\n",
    "\n",
    "    perform_proportion_analysis(dat, 'cor_sos', \"SoS\")\n",
    "    perform_proportion_analysis(dat, 'cor_ca', \"CA\")\n",
    "    perform_proportion_analysis(dat, 'cor_ce', \"CE\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
