{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The code aims to modify the analysis of Yenni et al. (2012):\n",
    "#### - corrected the SoS calculation\n",
    "#### - modified the parameters to paper's description: \"r2 integers from 11 to 20\"\n",
    "#### - removed the additional filter S1 >= 1 & S2 >= 1\n",
    "#### - did not truncate the values\n",
    "#### - included additional metrics: CA and CE\n",
    "#### - employed PCA to the variables\n",
    "\n",
    "#### their original code: https://github.com/gmyenni/RareStabilizationSimulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analyN_function.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyN(r1, r2, a1, a12, a21, a2):\n",
    "    N1 = (r1 - 1 - (a12 / a2) * (r2 - 1)) / (a1 - a21 * a12 / a2)\n",
    "    N2 = (r2 - 1 - (a21 / a1) * (r1 - 1)) / (a2 - a21 * a12 / a1)\n",
    "    \n",
    "    if np.isinf(N1) or np.isinf(N2) or np.isnan(N1) or np.isnan(N2):\n",
    "        initialNsp1 = 0\n",
    "        initialNsp2 = 0\n",
    "        N = np.zeros((100, 2))\n",
    "        N[0, :] = [initialNsp1, initialNsp2]\n",
    "        \n",
    "        for i in range(1, 100):\n",
    "            N[i, 0] = max((r1 - 1 - a12 * N[i-1, 1]) / a1, 0)\n",
    "            N[i, 1] = max((r2 - 1 - a21 * N[i-1, 0]) / a2, 0)\n",
    "        \n",
    "        N1 = np.mean(N[:, 0])\n",
    "        N2 = np.mean(N[:, 1])\n",
    "    \n",
    "    if N1 < 0 and N2 >= 0:\n",
    "        N1 = 0\n",
    "        N2 = (r2 - 1) / a2\n",
    "    elif N2 < 0 and N1 >= 0:\n",
    "        N2 = 0\n",
    "        N1 = (r1 - 1) / a1\n",
    "    \n",
    "    return N1, N2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def competitive_ability(r1, r2, a11, a22, a12, a21):\n",
    "    CA1 = (r1 - 1) / np.sqrt(a12 * a11)\n",
    "    CA2 = (r2 - 1) / np.sqrt(a21 * a22)\n",
    "    return CA1, CA2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# getNFD.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(l1, l2, a11, a12, a21, a22, N1, N2):\n",
    "    CoexistRank = 0 if N1 < 1 else 1\n",
    "\n",
    "#     The code of Yenni et al. replaced l1 with l2 in the numerator:\n",
    "#     S1 = l2 / (1 + (a12 / a22) * (l2 - 1))\n",
    "#     S2 = l1 / (1 + (a21 / a11) * (l1 - 1))\n",
    "#     # Corrected Strength of Stabilization:\n",
    "    S1 = l1 / (1 + (a12 / a22) * (l2 - 1))\n",
    "    S2 = l2 / (1 + (a21 / a11) * (l1 - 1))\n",
    "\n",
    "    E1, E2 = l1 / l2, l2 / l1  # Fitness equivalence\n",
    "    Asy = S1 - S2  # Asymmetry\n",
    "    Rare = 0 if N1 == 0 and N2 == 0 else N1 / (N1 + N2)\n",
    "\n",
    "    # Calculating covariance for SoS\n",
    "    x = np.array([N1, N2])\n",
    "    y_sos = np.array([S1, S2])\n",
    "    cor_matrix_sos = np.cov(x, y_sos)\n",
    "    cor_sos = cor_matrix_sos[0, 1]  # Extracting the correlation between N and SoS\n",
    "\n",
    "    Rank = 0 if N1 == 0 and N2 == 0 else (2 if N1 / (N1 + N2) <= 0.25 else 1)\n",
    "\n",
    "    # Competitive Ability\n",
    "    CA1, CA2 = competitive_ability(l1, l2, a11, a22, a12, a21)\n",
    "\n",
    "    # Calculating covariance for CA\n",
    "    y_ca = np.array([CA1, CA2])\n",
    "    cor_matrix_ca = np.cov(x, y_ca)\n",
    "    cor_ca = cor_matrix_ca[0, 1]  # Extracting the correlation between N and CA\n",
    "\n",
    "    return {\"CoexistRank\": CoexistRank, \"E1\": E1, \"S1\": S1, \"E2\": E2, \"S2\": S2, \"Asy\": Asy, \"cor_sos\": cor_sos, \"cor_ca\": cor_ca, \"Rare\": Rare, \"Rank\": Rank, \"CA1\": CA1, \"CA2\": CA2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# annualplant_2spp_det_par.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data():\n",
    "    # Defines frequency-dependent parameters\n",
    "    l1_v = np.arange(15, 21)\n",
    "    l2_v = np.arange(15, 21)\n",
    "    a11_v = np.array([0.1, 0.3, 0.5, 0.7, 0.9, 1, 1.5, 2, 2.5, 3])\n",
    "    a12_v = np.array([0.1, 0.3, 0.5, 0.7, 0.9, 1])\n",
    "    a21_v = np.array([0.1, 0.3, 0.5, 0.7, 0.9, 1])\n",
    "    a22_v = np.array([0.1, 0.3, 0.5, 0.7, 0.9, 1])\n",
    "\n",
    "    # Generate all combinations of parameters using NumPy's meshgrid\n",
    "    mesh = np.array(np.meshgrid(l1_v, l2_v, a11_v, a12_v, a21_v, a22_v)).T.reshape(-1, 6)\n",
    "    return mesh\n",
    "\n",
    "def Sim(k, mesh_row):\n",
    "    l1, l2, a11, a12, a21, a22 = mesh_row\n",
    "    N1, N2 = analyN(l1, l2, a11, a12, a21, a22)\n",
    "    metrics = calculate_metrics(l1, l2, a11, a12, a21, a22, N1, N2)\n",
    "    return {**metrics, \"l1\": l1, \"l2\": l2, \"a11\": a11, \"a12\": a12, \"a21\": a21, \"a22\": a22}\n",
    "\n",
    "def postprocess_results(results, outfile):\n",
    "    column_order = ['l1', 'l2', 'a11', 'a12', 'a21', 'a22', 'N1', 'N2', 'E1', 'S1', 'E2', 'S2', 'Rank', 'CoexistRank', 'Asy', 'cor_sos', 'cor_ca', 'Rare', 'CA1', 'CA2']\n",
    "    simul = pd.DataFrame(results, columns=column_order)\n",
    "    simul.to_csv(outfile, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cor_figure.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cor_figure():\n",
    "    dat_det = pd.read_csv(\"csv/annplant_2spp_det_rare.csv\")\n",
    "    dat_det = dat_det.query('Rank == 2').copy() #  & S1 >= 1 & S2 >= 1\n",
    "    dat_det.reset_index(drop=True, inplace=True)\n",
    "#     dat_det = np.trunc(dat_det * 100) / 100.0\n",
    "    dat_det.sort_values(by=['a22', 'a21', 'a12', 'a11', 'l2', 'l1'], inplace=True)\n",
    "    dat_det.to_csv(\"csv/annplant_2spp_det_rare_filtered.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pca(simul):\n",
    "    # Apply PCA to SoS and FE\n",
    "    features_sos_fe = ['S1', 'S2', 'E1', 'E2']\n",
    "    x_sos_fe = StandardScaler().fit_transform(simul[features_sos_fe].values)\n",
    "    pca_sos_fe = PCA(n_components=2)\n",
    "    principalComponents_sos_fe = pca_sos_fe.fit_transform(x_sos_fe)\n",
    "    simul[['SoS_PCA', 'FE_PCA']] = principalComponents_sos_fe\n",
    "    \n",
    "    # Apply PCA to CA\n",
    "    features_ca = ['CA1', 'CA2']\n",
    "    x_ca = StandardScaler().fit_transform(simul[features_ca].values)\n",
    "    pca_ca = PCA(n_components=1)\n",
    "    principalComponent_ca = pca_ca.fit_transform(x_ca)\n",
    "    simul['CA_PCA'] = principalComponent_ca\n",
    "    \n",
    "    return simul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# figures_det.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_logistic_regression(dat, analysis_type):\n",
    "    predictors_map = {\n",
    "        'PCA_SoS': ['SoS_PCA', 'cor_sos'],\n",
    "        'PCA_CA': ['CA_PCA', 'cor_ca'],\n",
    "        'NonPCA_SoS': ['S1', 'E1', 'cor_sos'],\n",
    "        'NonPCA_CA': ['CA1', 'CA2', 'cor_ca']\n",
    "    }\n",
    "    predictors = predictors_map[analysis_type]\n",
    "    X = sm.add_constant(dat[predictors])\n",
    "    y = dat['CoexistRank']\n",
    "    model = sm.GLM(y, X, family=sm.families.Binomial())\n",
    "    result = model.fit()\n",
    "    print(f\"{analysis_type} Analysis:\\n{result.summary()}\")\n",
    "    return result\n",
    "\n",
    "def calculate_proportions(dat, correlation_type):\n",
    "    proportions = {}\n",
    "    for cor_type in ['cor_sos', 'cor_ca']:\n",
    "        proportions[f'positive_coexistence_{cor_type}'] = len(dat[(dat[cor_type] >= 0) & (dat['CoexistRank'] == 1)])\n",
    "        proportions[f'positive_exclusion_{cor_type}'] = len(dat[(dat[cor_type] >= 0) & (dat['CoexistRank'] == 0)])\n",
    "        proportions[f'negative_coexistence_{cor_type}'] = len(dat[(dat[cor_type] < 0) & (dat['CoexistRank'] == 1)])\n",
    "        proportions[f'negative_exclusion_{cor_type}'] = len(dat[(dat[cor_type] < 0) & (dat['CoexistRank'] == 0)])\n",
    "    return proportions\n",
    "\n",
    "def report_coexistence_analysis(proportions):\n",
    "    for cor_type in ['cor_sos', 'cor_ca']:\n",
    "        positive_key = f'positive_coexistence_{cor_type}'\n",
    "        negative_key = f'negative_coexistence_{cor_type}'\n",
    "        neg_confint = proportion_confint(count=proportions[negative_key], nobs=proportions[negative_key] + proportions[f'negative_exclusion_{cor_type}'], alpha=0.05, method='wilson')\n",
    "        pos_confint = proportion_confint(count=proportions[positive_key], nobs=proportions[positive_key] + proportions[f'positive_exclusion_{cor_type}'], alpha=0.05, method='wilson')\n",
    "        print(f\"\\nAnalysis on Negative \\u03BD for {cor_type.upper()}:\")\n",
    "        print(f\"Proportion of coexistence with \\u03BD < 0: {proportions[negative_key] / (proportions[negative_key] + proportions[f'negative_exclusion_{cor_type}']):.4f} (95% CI: {neg_confint})\")\n",
    "        print(f\"Proportion of coexistence with \\u03BD \\u2265 0: {proportions[positive_key] / (proportions[positive_key] + proportions[f'positive_exclusion_{cor_type}']):.4f} (95% CI: {pos_confint})\")\n",
    "\n",
    "def analyze_coexistence_effect(file_path, use_pca=False):\n",
    "    dat = pd.read_csv(file_path)\n",
    "    if use_pca:\n",
    "        dat = apply_pca(dat)\n",
    "    models_results = {}\n",
    "    analysis_types = ['PCA_SoS', 'PCA_CA'] if use_pca else ['NonPCA_SoS', 'NonPCA_CA']\n",
    "    for analysis_type in analysis_types:\n",
    "        # Conduct logistic regression and display summary\n",
    "        result = perform_logistic_regression(dat, analysis_type)\n",
    "        # Calculate AIC, AICc, and BIC for model selection purposes\n",
    "        aic = result.aic\n",
    "        bic = result.bic\n",
    "        n = len(dat)  # Number of observations\n",
    "        k = len(result.params)  # Number of parameters\n",
    "        aicc = aic + (2 * k * (k + 1)) / (n - k - 1)\n",
    "        # Store AIC, AICC, and BIC values for each model for later comparison\n",
    "        models_results[analysis_type] = (aic, aicc, bic)\n",
    "    proportions = calculate_proportions(dat, 'cor_sos' if 'cor_sos' in dat.columns else 'cor_ca')\n",
    "    report_coexistence_analysis(proportions)\n",
    "    correlation_type = 'cor_sos' if 'cor_sos' in dat.columns else 'cor_ca'\n",
    "    table_data = {\n",
    "        '\\u03BD \\u2265 0': [proportions[f'positive_coexistence_{correlation_type}'], proportions[f'positive_exclusion_{correlation_type}']],\n",
    "        '\\u03BD < 0': [proportions[f'negative_coexistence_{correlation_type}'], proportions[f'negative_exclusion_{correlation_type}']]\n",
    "    }\n",
    "    table_df = pd.DataFrame(table_data, index=['coexistence', 'exclusion'])\n",
    "    print(\"\\nCoexistence and Exclusion based on \\u03BD:\\n\", table_df)\n",
    "    for analysis_type in analysis_types:\n",
    "        for coexistence_type in ['positive', 'negative']:\n",
    "            coexist_col = f'{coexistence_type}_coexistence_{correlation_type}'\n",
    "            total_col = f'{coexistence_type}_exclusion_{correlation_type}'\n",
    "            proportion = proportions[coexist_col] / (proportions[coexist_col] + proportions[total_col]) if (proportions[coexist_col] + proportions[total_col]) > 0 else 0\n",
    "            confint = proportion_confint(count=proportions[coexist_col], nobs=proportions[coexist_col] + proportions[total_col], alpha=0.05, method='wilson')\n",
    "            print(f\"\\nProportion of {coexistence_type} coexistence with {analysis_type}: {proportion:.4f} (95% CI: {confint})\")\n",
    "            # Decision making based on confidence intervals\n",
    "            if coexistence_type == 'negative':\n",
    "                if confint[1] < 0.5:  # Assuming a threshold of 0.5 for decision making\n",
    "                    print(f\"Higher coexistence observed with \\u03BD \\u2265 0 for {analysis_type}, not supporting the authors' claim.\")\n",
    "                elif confint[0] > 0.5:\n",
    "                    print(f\"Higher coexistence observed with \\u03BD < 0 for {analysis_type}, supporting the authors' claim.\")\n",
    "                else:\n",
    "                    print(f\"Confidence intervals for proportions overlap for {analysis_type}, suggesting the effect of \\u03BD on coexistence is inconclusive.\")\n",
    "    return models_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_selection(models_results):\n",
    "    # Initialize variables to store the best scores and corresponding models\n",
    "    best_aic, best_aicc, best_bic = float('inf'), float('inf'), float('inf')\n",
    "    best_model_aic, best_model_aicc, best_model_bic = None, None, None\n",
    "    # Loop through each model to find the best ones based on AIC, AICc, and BIC\n",
    "    for model, (aic, aicc, bic) in models_results.items():\n",
    "        if aic < best_aic:\n",
    "            best_aic = aic\n",
    "            best_model_aic = model\n",
    "        if aicc < best_aicc:\n",
    "            best_aicc = aicc\n",
    "            best_model_aicc = model\n",
    "        if bic < best_bic:\n",
    "            best_bic = bic\n",
    "            best_model_bic = model\n",
    "    print(f\"\\nBest model based on AIC: {best_model_aic} (AIC: {best_aic})\")\n",
    "    print(f\"Best model based on AICc: {best_model_aicc} (AICc: {best_aicc})\")\n",
    "    print(f\"Best model based on BIC: {best_model_bic} (BIC: {best_bic})\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis with Original Variables:\n",
      "NonPCA_SoS Analysis:\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:            CoexistRank   No. Observations:                39203\n",
      "Model:                            GLM   Df Residuals:                    39199\n",
      "Model Family:                Binomial   Df Model:                            3\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -20159.\n",
      "Date:                Tue, 26 Mar 2024   Deviance:                       40318.\n",
      "Time:                        14:41:20   Pearson chi2:                 1.49e+05\n",
      "No. Iterations:                     6   Pseudo R-squ. (CS):             0.2187\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -2.9040      0.094    -30.769      0.000      -3.089      -2.719\n",
      "S1             1.4732      0.024     62.573      0.000       1.427       1.519\n",
      "E1             0.5813      0.088      6.582      0.000       0.408       0.754\n",
      "cor_sos       -0.0026      0.000    -15.431      0.000      -0.003      -0.002\n",
      "==============================================================================\n",
      "NonPCA_CA Analysis:\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:            CoexistRank   No. Observations:                39203\n",
      "Model:                            GLM   Df Residuals:                    39199\n",
      "Model Family:                Binomial   Df Model:                            3\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -23966.\n",
      "Date:                Tue, 26 Mar 2024   Deviance:                       47931.\n",
      "Time:                        14:41:21   Pearson chi2:                 3.98e+04\n",
      "No. Iterations:                     7   Pseudo R-squ. (CS):            0.05126\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.4124      0.025    -16.447      0.000      -0.461      -0.363\n",
      "CA1           -0.0103      0.001    -18.349      0.000      -0.011      -0.009\n",
      "CA2            0.0050      0.001      7.443      0.000       0.004       0.006\n",
      "cor_ca        -0.0004   1.64e-05    -26.217      0.000      -0.000      -0.000\n",
      "==============================================================================\n",
      "\n",
      "Analysis on Negative ν for COR_SOS:\n",
      "Proportion of coexistence with ν < 0: 0.3223 (95% CI: (0.31256571140419276, 0.3322466227901977))\n",
      "Proportion of coexistence with ν ≥ 0: 0.3385 (95% CI: (0.33324200845529894, 0.343855677145823))\n",
      "\n",
      "Analysis on Negative ν for COR_CA:\n",
      "Proportion of coexistence with ν < 0: 0.3231 (95% CI: (0.31334616442632984, 0.333028194238238))\n",
      "Proportion of coexistence with ν ≥ 0: 0.3383 (95% CI: (0.3330253474756408, 0.3436390945744438))\n",
      "\n",
      "Coexistence and Exclusion based on ν:\n",
      "              ν ≥ 0  ν < 0\n",
      "coexistence  10339   2792\n",
      "exclusion    20202   5870\n",
      "\n",
      "Proportion of positive coexistence with NonPCA_SoS: 0.3385 (95% CI: (0.33324200845529894, 0.343855677145823))\n",
      "\n",
      "Proportion of negative coexistence with NonPCA_SoS: 0.3223 (95% CI: (0.31256571140419276, 0.3322466227901977))\n",
      "Higher coexistence observed with ν ≥ 0 for NonPCA_SoS, not supporting the authors' claim.\n",
      "\n",
      "Proportion of positive coexistence with NonPCA_CA: 0.3385 (95% CI: (0.33324200845529894, 0.343855677145823))\n",
      "\n",
      "Proportion of negative coexistence with NonPCA_CA: 0.3223 (95% CI: (0.31256571140419276, 0.3322466227901977))\n",
      "Higher coexistence observed with ν ≥ 0 for NonPCA_CA, not supporting the authors' claim.\n",
      "\n",
      "Analysis with PCA Components:\n",
      "PCA_SoS Analysis:\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:            CoexistRank   No. Observations:                39203\n",
      "Model:                            GLM   Df Residuals:                    39200\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -23580.\n",
      "Date:                Tue, 26 Mar 2024   Deviance:                       47161.\n",
      "Time:                        14:41:22   Pearson chi2:                 3.94e+04\n",
      "No. Iterations:                     6   Pseudo R-squ. (CS):            0.06972\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.3657      0.013    -28.715      0.000      -0.391      -0.341\n",
      "SoS_PCA        0.0467      0.008      5.854      0.000       0.031       0.062\n",
      "cor_sos       -0.0071      0.000    -36.329      0.000      -0.008      -0.007\n",
      "==============================================================================\n",
      "PCA_CA Analysis:\n",
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:            CoexistRank   No. Observations:                39203\n",
      "Model:                            GLM   Df Residuals:                    39200\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -24064.\n",
      "Date:                Tue, 26 Mar 2024   Deviance:                       48128.\n",
      "Time:                        14:41:22   Pearson chi2:                 3.90e+04\n",
      "No. Iterations:                     6   Pseudo R-squ. (CS):            0.04649\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.5733      0.011    -50.865      0.000      -0.595      -0.551\n",
      "CA_PCA        -0.1655      0.013    -13.052      0.000      -0.190      -0.141\n",
      "cor_ca        -0.0003   9.34e-06    -28.989      0.000      -0.000      -0.000\n",
      "==============================================================================\n",
      "\n",
      "Analysis on Negative ν for COR_SOS:\n",
      "Proportion of coexistence with ν < 0: 0.3223 (95% CI: (0.31256571140419276, 0.3322466227901977))\n",
      "Proportion of coexistence with ν ≥ 0: 0.3385 (95% CI: (0.33324200845529894, 0.343855677145823))\n",
      "\n",
      "Analysis on Negative ν for COR_CA:\n",
      "Proportion of coexistence with ν < 0: 0.3231 (95% CI: (0.31334616442632984, 0.333028194238238))\n",
      "Proportion of coexistence with ν ≥ 0: 0.3383 (95% CI: (0.3330253474756408, 0.3436390945744438))\n",
      "\n",
      "Coexistence and Exclusion based on ν:\n",
      "              ν ≥ 0  ν < 0\n",
      "coexistence  10339   2792\n",
      "exclusion    20202   5870\n",
      "\n",
      "Proportion of positive coexistence with PCA_SoS: 0.3385 (95% CI: (0.33324200845529894, 0.343855677145823))\n",
      "\n",
      "Proportion of negative coexistence with PCA_SoS: 0.3223 (95% CI: (0.31256571140419276, 0.3322466227901977))\n",
      "Higher coexistence observed with ν ≥ 0 for PCA_SoS, not supporting the authors' claim.\n",
      "\n",
      "Proportion of positive coexistence with PCA_CA: 0.3385 (95% CI: (0.33324200845529894, 0.343855677145823))\n",
      "\n",
      "Proportion of negative coexistence with PCA_CA: 0.3223 (95% CI: (0.31256571140419276, 0.3322466227901977))\n",
      "Higher coexistence observed with ν ≥ 0 for PCA_CA, not supporting the authors' claim.\n",
      "\n",
      "Best model based on AIC: NonPCA_SoS (AIC: 40325.77941117084)\n",
      "Best model based on AICc: NonPCA_SoS (AICc: 40325.78043163107)\n",
      "Best model based on BIC: NonPCA_SoS (BIC: -374270.77937600494)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    # Specify paths for the output files\n",
    "    initial_output_file = \"csv/annplant_2spp_det_rare.csv\"\n",
    "    filtered_output_file = \"csv/annplant_2spp_det_rare_filtered.csv\"\n",
    "    pca_output_file = \"csv/annplant_2spp_det_rare_with_pca.csv\"\n",
    "    \n",
    "    # Generate the parameter mesh\n",
    "    mesh = preprocess_data()\n",
    "    \n",
    "    # Run the simulation for each parameter set in the mesh\n",
    "    results = [Sim(k, row) for k, row in enumerate(mesh)]\n",
    "    \n",
    "    # Convert the list of dictionaries into a DataFrame and save to CSV\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv(initial_output_file, index=False)\n",
    "\n",
    "    # Apply filters and generate the filtered data CSV\n",
    "    cor_figure()\n",
    "\n",
    "    # Initialize dictionary for model results\n",
    "    models_results = {}\n",
    "\n",
    "    # Analysis without PCA using the filtered dataset\n",
    "    print(\"Analysis with Original Variables:\")\n",
    "    # Adjust analyze_coexistence_effect to return model names and their scores\n",
    "    non_pca_results = analyze_coexistence_effect(filtered_output_file, use_pca=False)\n",
    "    models_results.update(non_pca_results)\n",
    "\n",
    "    # Load the filtered dataset, apply PCA, and perform analysis\n",
    "    simul = pd.read_csv(filtered_output_file)\n",
    "    simul_with_pca = apply_pca(simul)\n",
    "    simul_with_pca.to_csv(pca_output_file, index=False)\n",
    "    \n",
    "    print(\"\\nAnalysis with PCA Components:\")\n",
    "    # Adjust analyze_coexistence_effect to return model names and their scores\n",
    "    pca_results = analyze_coexistence_effect(pca_output_file, use_pca=True)\n",
    "    models_results.update(pca_results)\n",
    "\n",
    "    # Model Selection based on AIC, AICc, and BIC\n",
    "    model_selection(models_results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
